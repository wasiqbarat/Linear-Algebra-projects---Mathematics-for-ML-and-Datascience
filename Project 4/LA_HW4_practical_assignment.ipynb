{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Algebra HW4 Practical Assignment\n",
        "_Author_: **AmirMohammad Babaei** \\\n",
        "_Telegram ID_: [@Amir_fal_01](t.me/Amir_fal_01) \\\n",
        "_Email_: [Amirmohamad.babaei79@gmail.com](mailto:Amirmohamad.babaei79@gmail.com)"
      ],
      "metadata": {
        "id": "8b2jB-5xY3YB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Student Name_: [Your Name] \\\n",
        "_Student ID_: [Your SID] \\"
      ],
      "metadata": {
        "id": "vNY4KEUN3nq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to complete this notebook?\n",
        "To complete this notebook you just need to change the parts of code that is marked by comment `#CHNAGE THIS PART`. Please do not change cells that contains comment `# DO NOT CHANGE THIS CELL`. These cells are for evaluating your implementation."
      ],
      "metadata": {
        "id": "iJQFE5_cD1VB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eigenvalues and Eigenvectors\n",
        "In chapter 5 of textbook, you have read about eigenvalues and their corresponding eigenvectors. As you know, eigenvalues are defined as below:\n",
        "$$A\\mathbf{v}=\\lambda \\mathbf{v}$$\n",
        "such that $A \\in \\mathbb{R}^{n\\times n}$ square matrix, $\\mathbf{v}\\in\\mathbb{R}^n$, and $\\lambda \\in \\mathbb{R}$.\n"
      ],
      "metadata": {
        "id": "DOyqIcbtY3S6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Power Method\n",
        "The **power method** is an iterative algorithm used in linear algebra to find the dominant eigenvalue and its corresponding eigenvector of a square matrix. The dominant eigenvalue is the eigenvalue with the largest absolute value. Here are the steps for the power method:\n",
        "\n",
        "1. Choose an initial guess for the eigenvector of the dominant eigenvalue, denoted by $\\mathbf{x}_0$​.\n",
        "2. Multiply the matrix $A$ by the initial guess to get a new vector: $\\mathbf{y}_1=A\\mathbf{x}_0$.\n",
        "3. Normalize the new vector by dividing it by its largest component: $\\mathbf{x}_1=\\frac{\\mathbf{y}_1}{\\max_⁡{i} |\\mathbf{y}_{1,i}|}$.\n",
        "4. Repeat steps 2 and 3 with the new vector to get the next approximation: $\\mathbf{y}_2=A\\mathbf{x}_1$ and $\\mathbf{x}_2=\\frac{\\mathbf{y}_2}{\\max_⁡i |\\mathbf{y}_{2, i}|}$.\n",
        "5. Continue this process until the sequence of approximations converges to the dominant eigenvector.\n",
        "\n",
        "The dominant eigenvalue can be estimated by computing the Rayleigh quotient, which is the ratio of the dot product of the current approximation and the matrix product of the current approximation with the matrix, to the dot product of the current approximation with itself. The Rayleigh quotient converges to the dominant eigenvalue as the sequence of approximations converges to the dominant eigenvector. \n",
        "### How Power Method helps us?\n",
        "The power method is useful for large matrices because it only requires matrix-vector multiplication, which can be done efficiently using parallel computing. However, it only finds the dominant eigenvalue and its corresponding eigenvector, and it may converge slowly if there are eigenvalues close in magnitude to the dominant eigenvalue."
      ],
      "metadata": {
        "id": "v65rPJp--5MC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "e08Ljd8khJKI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1jel5nJYS43"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Base Class for Power Method"
      ],
      "metadata": {
        "id": "OD8Y-nqkF8Rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseMethod:\n",
        "\n",
        "    def __init__(self, iterations):\n",
        "        \"\"\"\n",
        "        Initialize PowerMethod object\n",
        "\n",
        "        Args:\n",
        "            iterations: number of iterations of algorithm\n",
        "        \"\"\"\n",
        "        self.iterations = iterations\n",
        "\n",
        "    def __call__(self, \n",
        "                 matrix: np.ndarray, \n",
        "                 x: np.ndarray) -> Tuple[np.float64, np.ndarray]:\n",
        "        raise NotImplementedError('The Object call() not defined yet.')\n",
        "\n",
        "    # COMPLETE THIS METHOD\n",
        "    def normalize(self, x: np.ndarray) -> Tuple[np.float64, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Normalize $A \\mathbf{x}_k$\n",
        "\n",
        "        Args:\n",
        "            x: result of matrix-vector product ($A \\mathbf{x}_k$)\n",
        "\n",
        "        Returns:\n",
        "            fac: maximum absolute value in `x` vector\n",
        "            x_n: normalized input `x` vector ($\\mathbf{x}_{k+1}$)\n",
        "\n",
        "        Raises:\n",
        "            ZeroDivisionError: raise if maximum absolute value be close to zero\n",
        "        \"\"\"\n",
        "\n",
        "        #################################################\n",
        "        # compute maximum absolute value of the vector x\n",
        "        #################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "\n",
        "        #################################################\n",
        "        # check whether maximum absolute value is zero\n",
        "        #################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "\n",
        "        #################################################\n",
        "        # compute x_n \n",
        "        #################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "GHGYrDLbFgAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Power Method\n"
      ],
      "metadata": {
        "id": "NIBLNx6GhN51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The power method applies to an $n\\times n$ matrix $A$ with a **strictly dominant eigenvalue** $\\lambda_1$, which means that $\\lambda_1$ must be larger in absolute value than all the other eigenvalues.\n",
        "In this case, the power method produces a scalar sequence that approaches \u00151 and a vector sequence that approaches a corresponding eigenvector. The background for the method rests on the __eigenvector decomposition__ used at the beginning of Section 5.6 of textbook. \\\n",
        "Assume for simplicity that $A$ is diagonalizable and $\\mathbb{R}^n$ has a basis of eigenvectors $\\mathbf{v}_1, \\dots, \\mathbf{v}_n$, arranged so their corresponding eigenvalues $\\lambda_1, \\dots, \\lambda_n$ decrease in size, with\n",
        "the strictly dominant eigenvalue first. That is,\n",
        "$$|\\lambda_1| > |\\lambda_2| \\ge |\\lambda_3| \\ge \\cdots \\ge |\\lambda_n| $$"
      ],
      "metadata": {
        "id": "R1EU7Zw5rfYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PowerMethod(BaseMethod):\n",
        "    \"\"\"\n",
        "    Implementation of Power Method to compute dominant eigenvalue and corresponding\n",
        "    eigenvector.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, iterations):\n",
        "        \"\"\"\n",
        "        Initialize PowerMethod object\n",
        "\n",
        "        Args:\n",
        "            iterations: number of iterations of algorithm\n",
        "        \"\"\"\n",
        "        super(PowerMethod, self).__init__(iterations)\n",
        "\n",
        "    # COMPLETE THIS METHOD\n",
        "    def __call__(self, \n",
        "                 matrix: np.ndarray, \n",
        "                 x: np.ndarray) -> Tuple[np.float64, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Call PowerMethod object\n",
        "\n",
        "        Args:\n",
        "            matrix: the matrix we want to find its dominant eigenvalue\n",
        "            x: initial estimate of corresponding eigenvector \n",
        "                (max element must be 1 otherwise it's normalized using `x/x.max()`)\n",
        "\n",
        "        Returns:\n",
        "            lambda_1: dominant eigenvalue\n",
        "            x: corresponding eigenvector\n",
        "        \"\"\"\n",
        "        ##################################################\n",
        "        # assert squareness of matrix\n",
        "        ##################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "\n",
        "        ##############################################################\n",
        "        # check if max element value is not zero, normalize the vector\n",
        "        ##############################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "\n",
        "        ##################################################\n",
        "        # implement the loop and operations to compute it\n",
        "        ##################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "        "
      ],
      "metadata": {
        "id": "c4mM4SptFTx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS CELL\n",
        "# Test Power Method implementation\n",
        "x = np.array([0.5, 0.5])\n",
        "a = np.array([[0, 2], \n",
        "              [2, 3]])\n",
        "\n",
        "power_method = PowerMethod(15)\n",
        "lambda_1,  x = power_method(a, x)\n",
        "    \n",
        "print('Eigenvalue:', lambda_1)\n",
        "print('Eigenvector:', x)"
      ],
      "metadata": {
        "id": "4KwjuJNUc9f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output:\n",
        "\n",
        "    Eigenvalue: 4.000000003104409\n",
        "    Eigenvector: [0.5 1. ]"
      ],
      "metadata": {
        "id": "fXVQwAv7QS-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inverse Power Method"
      ],
      "metadata": {
        "id": "pL8BrOaihQn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The eigenvalues of the inverse matrix $A^{−1}$ are the reciprocals of the eigenvalues of $A$. We can take advantage of this feature as well as the power method to get the smallest eigenvalue of $A$, this will be basis of the inverse power method. The steps are very simple, instead of multiplying $A$ as described above, we just multiply $A^{−1}$ for our iteration to find the largest value of $\\frac{1}{λ_1}$, which will be the smallest value of the eigenvalues for $A$."
      ],
      "metadata": {
        "id": "qCUMkf1ePSb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InversePowerMethod(BaseMethod):\n",
        "    \"\"\"\n",
        "    Implementation of Inverse Power Method to compute dominant eigenvalue \n",
        "    of inverse matrix (which is the smallest one in main one if it isn't zero) \n",
        "    and corresponding eigenvector.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, iterations):\n",
        "        \"\"\"\n",
        "        Initialize InversePowerMethod object\n",
        "\n",
        "        Args:\n",
        "            iterations: number of iterations of algorithm\n",
        "        \"\"\"\n",
        "        super(InversePowerMethod, self).__init__(iterations)\n",
        "\n",
        "    # COMPLETE THIS METHOD\n",
        "    def __call__(self, \n",
        "                 matrix: np.ndarray, \n",
        "                 x: np.ndarray) -> Tuple[np.float64, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Call InversePowerMethod object\n",
        "\n",
        "        Args:\n",
        "            matrix: the matrix we want to find its dominant eigenvalue of its inverse\n",
        "            x: initial estimate of corresponding eigenvector \n",
        "                (max element must be 1 otherwise it's normalized using `x/x.max()`)\n",
        "\n",
        "        Returns:\n",
        "            lambda_1: dominant eigenvalue\n",
        "            x: corresponding eigenvector\n",
        "        \"\"\"\n",
        "        ##################################################\n",
        "        # assert squareness of matrix\n",
        "        ##################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "\n",
        "        #################################################\n",
        "        # compute inverse of input matrix\n",
        "        #################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "\n",
        "        ##############################################################\n",
        "        # check if max element value is not zero, normalize the vector\n",
        "        ##############################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "\n",
        "        ##################################################\n",
        "        # implement the loop and operations to compute it\n",
        "        ##################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "ccvs07AuNR95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT CHANGE THIS CELL\n",
        "#Test Inverse Power Method implementation\n",
        "x = np.array([0.5, 0.5])\n",
        "a = np.array([[0, 2], \n",
        "              [2, 3]])\n",
        "\n",
        "inverse_power_method = InversePowerMethod(15)\n",
        "lambda_1, x = inverse_power_method(a, x)\n",
        "    \n",
        "print('Eigenvalue:', lambda_1)\n",
        "print('Eigenvector:', x, '\\n')"
      ],
      "metadata": {
        "id": "2rnmIpLUQXMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output:\n",
        "\n",
        "    Eigenvalue: 0.9999999930150807\n",
        "    Eigenvector: [ 1.  -0.5]"
      ],
      "metadata": {
        "id": "EwE5gtZWQobv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shifted Power Method"
      ],
      "metadata": {
        "id": "spZHf0OqiKy_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases, we need to find all the eigenvalues and eigenvectors instead of the largest and smallest. One simple but inefficient way is to use the shifted power method (we will introduce you an efficient way in next section). Given $A\\mathbf{x}=λ\\mathbf{x}$, and $λ_1$ is the largest eigenvalue obtained by the power method, then we can have:\n",
        "$$[A−λ_1I]\\mathbf{x}=α\\mathbf{x}$$\n",
        "where $α$’s are the eigenvalues of the shifted matrix $A−λ_1I$, which will be $0,λ_2−λ_1,λ_3−λ_1, \\dots,λ_n−λ_1$.\n",
        "\n",
        "Now if we apply the power method to the shifted matrix, then we can determine the largest eigenvalue of the shifted matrix, i.e. $α_k$. Since $α_k=λ_k−λ_1$, we can get the eigenvalue $λ_k$ easily. We can repeat this process many times to find the all the other eigenvalues. But you can see that, it involves a lot of work! A better method for finding all the eigenvalues is to use the **QR method**, let’s see the next section how it works!"
      ],
      "metadata": {
        "id": "kLQH8PDfSbIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShiftedPowerMethod(BaseMethod):\n",
        "    \"\"\"\n",
        "    Implementation of Shifted Power Method to compute a non-dominant eigenvalue \n",
        "    and corresponding eigenvector.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, iterations):\n",
        "        \"\"\"\n",
        "        Initialize ShiftedPowerMethod object\n",
        "\n",
        "        Args:\n",
        "            iterations: number of iterations of algorithm\n",
        "        \"\"\"\n",
        "        super(ShiftedPowerMethod, self).__init__(iterations)\n",
        "\n",
        "    # COMPLETE THIS METHOD\n",
        "    def __call__(self, matrix: np.ndarray, \n",
        "                 x: np.ndarray, \n",
        "                 prev_lambda: np.float64) -> Tuple[np.float64, np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Call ShiftedPowerMethod object\n",
        "\n",
        "        Args:\n",
        "            matrix: the matrix we want to find its non-dominant eigenvalue\n",
        "            x: initial estimate of corresponding eigenvector \n",
        "                (max element must be 1 otherwise it's normalized using `x/x.max()`)\n",
        "            prev_lambda: last found dominant eigenvalue in the matrix\n",
        "\n",
        "        Returns:\n",
        "            lambda_k: non-dominant eigenvalue\n",
        "            x: corresponding eigenvector\n",
        "            new_matrix: matrix after subtraction of prev_lambda ($\\alpha = A - \\lambda_{\\text{prev}}I$)\n",
        "        \"\"\"\n",
        "        ##################################################\n",
        "        # assert squareness of matrix\n",
        "        ##################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "\n",
        "        ##################################################\n",
        "        # compute new matrix\n",
        "        ##################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "\n",
        "        ##############################################################\n",
        "        # check if max element value is not zero, normalize the vector\n",
        "        ##############################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "\n",
        "        ##################################################\n",
        "        # implement the loop and operations to compute it\n",
        "        ##################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "eJ_rPAEBt90t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS CELL\n",
        "# Test Shifted Power Method implementation\n",
        "x = np.array([0.5, 0.5])\n",
        "a = np.array([[0, 2], \n",
        "              [2, 3]])\n",
        "\n",
        "shifted_power_method = ShiftedPowerMethod(15)\n",
        "lambda_1, x, new_matrix = shifted_power_method(a, x, 4.)\n",
        "    \n",
        "print('Eigenvalue:', lambda_1)\n",
        "print('Eigenvector:', x, '\\n')\n",
        "print('New_matrix: ', new_matrix)"
      ],
      "metadata": {
        "id": "zilsgUgGVXMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output:\n",
        "\n",
        "    Eigenvalue: 1.0\n",
        "    Eigenvector: [ 1.  -0.5] \n",
        "\n",
        "    New_matrix:  [[-4.  2.]\n",
        "    [ 2. -1.]]"
      ],
      "metadata": {
        "id": "0mygkN1rSJO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QR Method\n",
        "\n",
        "The QR method is a preferred iterative method to find all the eigenvalues of a matrix (but not the eigenvectors at the same time). The idea is based on the following two concepts\n",
        "\n",
        "1. **Similar Matrices** will have the same eigenvalues and associated eigenvectors. Two square matrices $A$ and $B$ are similar if:\n",
        "\n",
        " $$A = C^{-1}BC$$\n",
        "\n",
        " where $C$ is an invertible matrix. \n",
        "\n",
        "2. The **QR method** is a way to decompose a matrix into two matrices $Q$ and $R$, where $Q$ is an orthogonal matrix, and $R$ is an upper triangular matrix. An orthogonal matrix has the features: $Q^{-1} = Q^T$, which means $Q^{-1}Q=Q^TQ=I$. \n",
        "\n",
        "How do we link these two concepts to find the eigenvalues? Say we\n",
        "have a matrix $A_0$ whose eigenvalues must be determined. At the $k$-th step (starting with $k = 0$), we can perform the QR decomposition and get $A_k = Q_kR_k$, where $Q_k$ is an orthogonal matrix and $R_k$ is an upper triangular matrix. We then form  $A_{k+1} = R_kQ_k$, which we note that \n",
        "\n",
        "$$A_{k+1} = R_kQ_k = Q^{-1}_kQ_kR_kQ_k = Q^{-1}_kA_kQ_k$$\n",
        "therefore, all the $A_k$ are similar, as we discussed above they all have the same eigenvalues. \n",
        "\n",
        "As the iteration goes, we will eventually converge to an upper triangular matrix form:\n",
        "\n",
        "$$ A_k = R_kQ_k = \\begin{bmatrix}\n",
        "\\lambda_1 & X & \\dots & X\\\\\n",
        "0 & \\lambda_2 & \\dots & X\\\\\n",
        "& &\\dots &\\\\\n",
        "0 & 0 & \\dots & \\lambda_n\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "where the diagonal values are the eigenvalues of the matrix. In each iteration of the QR method, factoring a matrix into an orthogonal and an upper triangular matrix can be done by using a special matrix called **Householder matrix**. We will go into the mathematical details how you get the $Q$ and $R$ from the matrix, so get ready!"
      ],
      "metadata": {
        "id": "LRXio6YeFfUV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gram-Schmidt Orthonormalization\n",
        "The Gram-Schmidt process takes a finite, linearly independent set of vectors and produces an orthonormal basis for the subspace they span. The process works by iteratively subtracting the projections of the vectors onto the previously computed orthonormal vectors, and then normalizing the resulting vectors to obtain the next orthonormal vector. The resulting orthonormal basis has the same span as the original set of vectors, but is easier to work with because the vectors are orthogonal and have unit length.\n",
        "The Algorithm steps are:\n",
        "\n",
        "1. Let $\\{\\mathbf{v}_1,\\mathbf{v}_2,…,\\mathbf{v}_n\\}$ be a set of linearly independent vectors in an inner product space.\n",
        "2. Define $\\mathbf{u}_1=\\frac{\\mathbf{v}_1}{∥\\mathbf{v}_1∥}$ as the first orthonormal vector.\n",
        "3. For $\\; i=2,3,\\dots,n \\;$ define $\\mathbf{u}_i=\\frac{\\mathbf{v}_i - \\sum_{j=1}^{i-1}{\\langle \\mathbf{v}_j\\;, \\;\\mathbf{u}_i \\rangle \\mathbf{u}_j}}{∥\\mathbf{v}_i - \\sum_{j=1}^{i-1}{\\langle \\mathbf{v}_j\\;, \\;\\mathbf{u}_i \\rangle \\mathbf{u}_j}∥}$ as the next orthonormal vector.\n",
        "4. The set $\\{\\mathbf{u}_1,\\mathbf{u}_2,…,\\mathbf{u}_n\\}$ is an orthonormal basis for the subspace spanned by $\\{\\mathbf{v}_1,\\mathbf{v}_2,…,\\mathbf{v}_n\\}$.\n"
      ],
      "metadata": {
        "id": "rX9jXSkxJR4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementation Note\n",
        "You can use numpy library functions to compute inner product and norm of vectors. Also, you can implement it from scratch, but there is no bonus for the implementation😞. \\\n",
        "*inner product*: `np.dot()`,  \n",
        "*vector norm*: `np.linalg.norm()`,\n",
        "\n",
        "**NOTE**: You can't use `np.linalg.qr()` function!!!\n"
      ],
      "metadata": {
        "id": "mfImf41sNbUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE THIS FUNCTION\n",
        "def gram_schmidt(A: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Implementation of Gram-Schmidt Algorithm\n",
        "\n",
        "    Args:\n",
        "        A (np.ndarray): 2D Matrix with linear independent columns\n",
        "\n",
        "    Returns:\n",
        "        orthonormal_A (np.ndarray): orthonormal 2D Matrix\n",
        "    \"\"\"\n",
        "    assert len(A.shape) == 2 , \"A should be a 2D Matrix\"\n",
        "    # CHANGE THIS PART\n",
        "    pass"
      ],
      "metadata": {
        "id": "ePWqyuBoFekl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE THIS FUNCTION\n",
        "def qr(A: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Implementation of QR Decomposition\n",
        "\n",
        "    Args:\n",
        "        A (np.ndarray): 2D Matrix with linear independent columns\n",
        "\n",
        "    Returns:\n",
        "        Q (np.ndarray): orthonormal 2D Matrix\n",
        "        R (np.ndarray): upper triangular 2D Matrix\n",
        "    \"\"\"\n",
        "    assert len(A.shape), \"A should be a 2D Matrix\"\n",
        "    # CHANGE THIS PART\n",
        "    pass"
      ],
      "metadata": {
        "id": "q-tPXdjMWLB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS CELL\n",
        "# Test qr() method\n",
        "a = np.array([[0, 2], \n",
        "              [2, 3]])\n",
        "\n",
        "q, r = qr(a)\n",
        "\n",
        "print('Q:', q)\n",
        "print('R:', r)\n",
        "\n",
        "b = np.dot(q, r)\n",
        "print('QR:', b)"
      ],
      "metadata": {
        "id": "rPU8HUrUYYGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output:\n",
        "\n",
        "    Q: [[0 1]\n",
        "    [1 0]]\n",
        "    R: [[2 3]\n",
        "    [0 2]]\n",
        "    QR: [[0 2]\n",
        "    [2 3]]"
      ],
      "metadata": {
        "id": "yBkgYqpDYsQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QR Method Eigenvalue Extraction"
      ],
      "metadata": {
        "id": "1rjShpvKc-Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QRMethod:\n",
        "    \"\"\"\n",
        "    Implementation of QR Method to compute all eigenvalues.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, iterations):\n",
        "        \"\"\"\n",
        "        Initialize QRMethod object\n",
        "\n",
        "        Args:\n",
        "            iterations: number of iterations of algorithm\n",
        "        \"\"\"\n",
        "        self.iterations = iterations\n",
        "\n",
        "    # COMPLETE THIS METHOD\n",
        "    def __call__(self, matrix: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Call QRMethod object\n",
        "\n",
        "        Args:\n",
        "            matrix(np.ndarray (float64)): the matrix we want to find its dominant eigenvalue\n",
        "\n",
        "        Returns:\n",
        "            diag_matrix(np.ndarray): diagonal matrix of eigenvalues\n",
        "        \"\"\"\n",
        "        ##################################################\n",
        "        # assert squareness of matrix\n",
        "        ##################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "\n",
        "        ##################################################\n",
        "        # implement the loop and operations to compute it\n",
        "        ##################################################\n",
        "        # CHANGE THIS PART\n",
        "        pass\n",
        "        "
      ],
      "metadata": {
        "id": "Qdp4ATj_Vxvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS CELL\n",
        "# Test QRMethod implementation\n",
        "a = np.array([[0, 2], \n",
        "              [2, 3]])\n",
        "\n",
        "qr_method = QRMethod(15)\n",
        "diag_a = qr_method(a)\n",
        "print(f'{diag_a=}')"
      ],
      "metadata": {
        "id": "LU6zeuBUZamE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected Output:\n",
        "\n",
        "    diag_a=array([[ 4.00000000e+00,  9.31322581e-09],\n",
        "        [ 9.31322575e-09, -1.00000000e+00]])"
      ],
      "metadata": {
        "id": "3l6qIxPwcdDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Step\n",
        "in this part, we want to check our implementation on a larger dataset (matrix) and check whether our implementation can find its eigenvalues and eigenvectors or not.\n",
        "Let's dive into the details of the matrix. Actually, we've got a `Gene-Gene Matrix` which holds data of system of genes. In the context of gene expression data, the projection of the data onto a principal component can be viewed as a gene-like pattern of expression across samples, and the normalized pattern is sometimes called an eigengene\n",
        ". Eigenvectors can be used to identify patterns in the data that are common across multiple genes, which can help to identify groups of genes that are co-regulated or involved in similar biological processes\n",
        ". The intuition behind eigenvectors is that they represent the directions in which the data varies the most, and the corresponding eigenvalues represent the amount of variation along those directions\n",
        ". By analyzing the eigenvectors and eigenvalues of a matrix of gene expression data, researchers can gain insights into the underlying biological processes that are driving the observed patterns of gene expression.\n",
        "\n",
        "$$\\begin{bmatrix}\n",
        "(gene_2, sample_1) & (gene_1, sample_2) & \\cdots & (gene_1, sample_n) \\\\\n",
        "(gene_2, sample_1) & (gene_2, sample_2) & \\cdots & (gene_2, sample_n) \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "(gene_n, sample_1) & (gene_n, sample_2) & \\cdots & (gene_n, sample_n) \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "The matrix, hold the interactions between genes and samples. "
      ],
      "metadata": {
        "id": "0XFWxwrVqcYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Gene-Gene Matrix"
      ],
      "metadata": {
        "id": "JkV_7RBMtrNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you're using Google Colab, you can upload the dataset by this command\n",
        "# otherwise, move the dataset file to the directory of the Jupyter Notebook\n",
        "from google.colab import files\n",
        "files.upload()                      # Select `gene-gene_matrix.npy file`\n",
        "\n",
        "mat = np.load(\"gene-gene_matrix.npy\")"
      ],
      "metadata": {
        "id": "5ngXpbB_z9Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find Dominant and other Eigenvectors"
      ],
      "metadata": {
        "id": "OfSTCbLvtv1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS CELL\n",
        "original_dominant_eigenvalue = 99.76940567631624\n",
        "original_dominant_eigenvector = np.array([0.90329122, 0.87885969, 0.86841458, 0.94982885, 0.9294041 ,\n",
        "                                0.91496194, 0.80344091, 0.82944884, 0.87628096, 0.84671726,\n",
        "                                0.85791444, 0.80819558, 0.94860853, 0.86305899, 0.87294054,\n",
        "                                0.95167473, 0.81161611, 0.84322824, 0.83977106, 0.91729978,\n",
        "                                0.9500072 , 0.92840364, 0.90058629, 0.90246557, 0.89395883,\n",
        "                                0.87612842, 0.80599595, 0.89017917, 0.86122412, 0.85760628,\n",
        "                                0.9134217 , 0.88182557, 0.85812396, 0.87742666, 0.86126678,\n",
        "                                0.96997732, 0.8885915 , 0.93847249, 0.9319629 , 0.9032271 ,\n",
        "                                0.8711509 , 0.86124095, 0.8928022 , 0.91271493, 0.86360068,\n",
        "                                0.90632789, 0.91763654, 0.81847848, 0.89385798, 0.810887  ,\n",
        "                                0.8999506 , 0.83292178, 0.73731823, 0.9113017 , 0.96373577,\n",
        "                                0.86075281, 0.91875472, 0.88560275, 0.95093262, 0.91534986,\n",
        "                                0.91587103, 0.87586729, 0.84603716, 0.90476357, 0.95180491,\n",
        "                                0.88791156, 0.83053998, 0.89581236, 0.92424733, 1.        ,\n",
        "                                0.89145225, 0.93418029, 0.80188942, 0.94526541, 0.79990191,\n",
        "                                0.93248885, 0.91252593, 0.93515361, 0.94812929, 0.87107699,\n",
        "                                0.96053874, 0.89562322, 0.87572204, 0.88884126, 0.89917072,\n",
        "                                0.92147855, 0.88449959, 0.91390545, 0.92728503, 0.92107635,\n",
        "                                0.87944927, 0.89307228, 0.92288612, 0.81330988, 0.87481499,\n",
        "                                0.74800799, 0.86736117, 0.87850893, 0.85700168, 0.9257728 ])\n",
        "\n",
        "power_method = PowerMethod(1000)\n",
        "dominant_eigenvalue, dominant_eigenvector = power_method(mat, np.array([1/100 for _ in range(100)]))\n",
        "np.testing.assert_allclose(dominant_eigenvalue, original_dominant_eigenvalue) # Eigenvalue\n",
        "np.testing.assert_allclose(dominant_eigenvector, original_dominant_eigenvector, rtol=1e-5) #Eigenvector\n",
        "print(\"All tests passed! :)\")"
      ],
      "metadata": {
        "id": "GecvQc1_vDpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS CELL\n",
        "original_dominant_inverse_eigenvalue = 13.265928816542875\n",
        "original_dominant_inverse_eigenvector = np.array([0.06323859,  0.24171843, -0.10241996,  0.68074692,  0.73905427,\n",
        "                                                -0.3230946 , -0.5678715 ,  0.04853379, -0.56919556, -0.0469231 ,\n",
        "                                                -0.48091412,  0.01514365,  0.27153318, -0.17202376,  0.01083346,\n",
        "                                                 0.07268218,  0.16278867, -0.35211238,  0.2369093 , -0.25015598,\n",
        "                                                -0.17643253, -0.23027   , -0.0365736 ,  0.61961911, -0.06446332,\n",
        "                                                -0.22393546,  0.06662966, -0.36159734,  0.47219928, -0.30246441,\n",
        "                                                -0.66771487, -0.02409939,  0.24305058, -0.49272252,  0.07663468,\n",
        "                                                 0.73601773,  0.20508252, -0.14416391,  0.14910619, -0.04035506,\n",
        "                                                -0.05899779, -0.08938951,  0.29346408,  0.39338638, -0.11736907,\n",
        "                                                 0.2190819 ,  0.27621342,  0.2353386 ,  0.24499447,  1.        ,\n",
        "                                                -0.01035272, -0.04000547,  0.17680639,  0.50499202, -0.09817686,\n",
        "                                                -0.25684654,  0.33139247, -0.01982955, -0.27776105,  0.57648918,\n",
        "                                                -0.27222926,  0.16100693, -0.20629083, -0.21591085, -0.61220395,\n",
        "                                                 0.66613115, -0.23084364, -0.16528288, -0.21331928, -0.66063534,\n",
        "                                                 0.31462107, -0.23815778, -0.56282922,  0.30140368,  0.24891656,\n",
        "                                                 0.23817498,  0.36740822,  0.05861054, -0.30523988,  0.40573243,\n",
        "                                                 0.49228818, -0.5427266 , -0.37026273,  0.27820465, -0.32251156,\n",
        "                                                -0.1028093 ,  0.18069916,  0.07999535,  0.20508022, -0.41054167,\n",
        "                                                -0.35698212, -0.14768179, -0.05008047, -0.05888245,  0.0588538 ,\n",
        "                                                -0.17821602,  0.64349215, -0.58680573, -0.4185832 , -0.28192999])\n",
        "\n",
        "inverse_power_method = InversePowerMethod(1000)\n",
        "dominant_inverse_eigenvalue, dominant_inverse_eigenvector = inverse_power_method(mat, np.array([1/100 for _ in range(100)]))\n",
        "np.testing.assert_allclose(dominant_inverse_eigenvalue, original_dominant_inverse_eigenvalue) # Eigenvalue\n",
        "np.testing.assert_allclose(dominant_inverse_eigenvector, original_dominant_inverse_eigenvector, rtol=1e-5) #Eigenvector\n",
        "print(\"All tests passed! :)\")"
      ],
      "metadata": {
        "id": "m4AmwzNIWgZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS CELL\n",
        "original_second_eigenvalue = 4.838555102276814\n",
        "original_second_eigenvector = np.array([-1.41544986e-01, -1.54147944e-01, -3.20195453e-01, -1.44568988e-01,\n",
        "                                         2.45246560e-01,  1.86627431e-02,  1.84185252e-01, -6.88761993e-01,\n",
        "                                        -3.89634859e-01,  4.77495713e-01, -1.01672842e-01,  3.06561397e-01,\n",
        "                                        -4.31945440e-01,  3.19989022e-01,  3.53156908e-02, -4.36222356e-01,\n",
        "                                        -2.86708050e-01,  1.65547166e-01,  2.18362770e-01, -3.47254210e-01,\n",
        "                                        -5.12005608e-01,  4.10519585e-01, -3.43762184e-01,  1.70001327e-01,\n",
        "                                        -7.08201856e-01, -6.08772079e-01,  5.96029081e-01, -5.20459474e-01,\n",
        "                                        -6.41569860e-01, -7.37515495e-01,  1.94353646e-01,  9.68674078e-03,\n",
        "                                        -1.25356843e-01,  4.13946554e-01,  7.35776997e-01,  5.96371674e-01,\n",
        "                                         9.90035386e-02,  1.77283892e-01, -1.05461240e-01,  7.75873784e-01,\n",
        "                                        -2.63609337e-01, -4.32748627e-01,  2.13624857e-02,  8.59613624e-04,\n",
        "                                        -6.92162702e-01,  7.89389611e-01, -3.25700963e-01,  3.22637554e-01,\n",
        "                                        -1.25348812e-01, -1.65321744e-01, -6.04767923e-01,  2.06370376e-01,\n",
        "                                         3.81659662e-01,  1.29802051e-02, -4.30388754e-01,  3.04035416e-01,\n",
        "                                         3.77257310e-02, -1.72400751e-01, -3.19229795e-01, -1.93791594e-01,\n",
        "                                         5.69561416e-01,  2.41871450e-01, -5.64855316e-01, -5.63952048e-01,\n",
        "                                         6.69025195e-02,  4.94845018e-01, -2.58318545e-01,  2.56172999e-02,\n",
        "                                        -2.58377776e-02,  1.83391802e-01,  2.42718860e-01, -6.03171876e-01,\n",
        "                                        -7.84608664e-01,  2.61109153e-01,  7.27513806e-01, -1.47921799e-01,\n",
        "                                         3.71352925e-01,  2.98748664e-01, -1.85798727e-02,  3.27150297e-01,\n",
        "                                        -7.38078347e-02,  2.11298143e-01,  3.24890634e-01,  4.03780053e-01,\n",
        "                                         2.64100405e-01, -7.36483819e-02,  3.45734722e-01,  3.26361520e-01,\n",
        "                                        -6.31732573e-01, -8.85939109e-01,  1.00000000e+00,  9.17887650e-02,\n",
        "                                         5.92647004e-01, -4.41268223e-01, -1.45305892e-01,  6.92241627e-01,\n",
        "                                         4.01154114e-01,  9.84403463e-02, -3.84552269e-01,  4.74180838e-01])\n",
        "\n",
        "shifted_power_method = ShiftedPowerMethod(1000)\n",
        "second_eigenvalue, second_eigenvector, new_mat = shifted_power_method(mat, np.array([1/100 for _ in range(100)]), 99.76940567631624)\n",
        "np.testing.assert_allclose(second_eigenvalue, original_second_eigenvalue) # Eigenvalue\n",
        "np.testing.assert_allclose(second_eigenvector, original_second_eigenvector, rtol=1e-5) #Eigenvector\n",
        "print(\"All tests passed! :)\")"
      ],
      "metadata": {
        "id": "jACfZKJkYPAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find All Eigenvalues"
      ],
      "metadata": {
        "id": "DW0UqapHt2jJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS CELL\n",
        "original_diag_eigenvalues = np.array([ 9.97694057e+01, -7.80310117e-01,  2.62660470e-01, -1.83890620e+00,\n",
        "                                    -6.31862065e-01, -4.93050975e+00, -1.15649195e+00, -1.58927934e+00,\n",
        "                                     4.59192697e+00,  3.99615330e+00,  4.66957547e+00,  1.38430999e+00,\n",
        "                                    -3.65446960e-01, -1.43607949e+00, -3.16084666e+00,  3.93971502e+00,\n",
        "                                     3.64107170e+00, -4.37283833e+00,  4.34669080e+00, -1.90246206e+00,\n",
        "                                    -1.90413752e+00, -4.27928785e+00, -3.51948456e+00, -1.88962266e-01,\n",
        "                                     1.28321263e+00,  2.32666051e+00,  3.93183557e+00,  2.43883982e+00,\n",
        "                                     2.52923853e+00,  4.03643897e+00, -1.93389675e+00, -2.43231840e+00,\n",
        "                                    -1.60055413e+00, -1.74893972e+00, -3.21787969e+00, -3.42814363e+00,\n",
        "                                     3.69861868e+00,  6.28358472e-01,  2.65267571e+00, -9.28326319e-01,\n",
        "                                     1.22713591e+00,  6.64784675e-01, -3.60533003e+00, -2.99413095e+00,\n",
        "                                     3.32384442e+00,  3.36077408e+00,  6.30292597e-01, -8.86918251e-01,\n",
        "                                     5.80162661e-02, -3.50396791e+00, -4.39151209e-01, -7.01640353e-02,\n",
        "                                     1.45370640e+00,  1.71157132e+00,  2.65639649e+00,  2.35522483e+00,\n",
        "                                     2.94534069e-01,  5.14568527e-01,  3.22300442e+00,  2.90968873e+00,\n",
        "                                    -2.39294170e+00, -1.58924164e+00, -3.07770770e+00, -2.85273573e+00,\n",
        "                                     8.62172278e-01,  1.16946140e+00,  2.85302182e+00, -2.82067289e+00,\n",
        "                                    -2.41575574e+00, -2.14693102e+00, -1.02861260e+00, -9.17858177e-01,\n",
        "                                    -5.79011382e-01, -6.45808725e-01, -2.02433399e+00, -1.39893319e+00,\n",
        "                                    -2.20507159e+00, -1.27976638e+00,  1.24765704e+00,  1.79954704e+00,\n",
        "                                     3.40500913e-01, -1.52939441e-01,  2.06545087e+00,  1.85403175e+00,\n",
        "                                     1.76444410e+00,  1.47670522e+00, -1.83794759e+00, -1.03827341e+00,\n",
        "                                    -7.47534389e-01,  5.60673031e-01,  9.05719124e-01,  4.40709597e-01,\n",
        "                                     4.42929233e-01, -1.33762462e+00,  7.32965495e-01,  9.71795552e-01,\n",
        "                                    -8.77781541e-01, -5.01736420e-01,  7.68705986e-01, -7.53810769e-02])\n",
        "\n",
        "qr_method = QRMethod(1000)\n",
        "diag_eigenvalues = np.diag(qr_method(mat), k=0)\n",
        "np.testing.assert_allclose(original_diag_eigenvalues, diag_eigenvalues, rtol=1e-5)\n",
        "print(\"All tests passed! :)\")"
      ],
      "metadata": {
        "id": "rXgaTcVbxqzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "- https://www.wolframalpha.com/input?input=power+method+linear+algebra+eigenvalues+eigenvectors\n",
        "- https://www.sciencedirect.com/topics/mathematics/power-method\n",
        "- https://ergodic.ugr.es/cphys/lecciones/fortran/power_method.pdf\n",
        "- https://en.wikipedia.org/wiki/Power_iteration\n",
        "- https://statisticaloddsandends.wordpress.com/2019/03/27/power-method-for-obtaining-the-top-eigenvector/\n",
        "- https://towardsdatascience.com/eigen-intuitions-understanding-eigenvectors-and-eigenvalues-630e9ef1f719"
      ],
      "metadata": {
        "id": "KM8gwYQjCS8O"
      }
    }
  ]
}